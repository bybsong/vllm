# Nginx Gateway for vLLM Nanonets-OCR
# Follows vLLM official deployment pattern
# Routes external traffic to internal vLLM containers

upstream vllm_backend {
    # Health checking
    least_conn;
    
    # vLLM container (internal network only)
    server vllm-nanonets-ocr:8000 max_fails=3 fail_timeout=30s;
    
    # Add more vLLM replicas here if needed:
    # server vllm-nanonets-ocr-2:8000 max_fails=3 fail_timeout=30s;
    # server vllm-nanonets-ocr-3:8000 max_fails=3 fail_timeout=30s;
}

server {
    listen 80;
    server_name _;

    # Increase timeouts for large OCR requests
    proxy_connect_timeout 300s;
    proxy_send_timeout 300s;
    proxy_read_timeout 300s;
    send_timeout 300s;

    # Increase body size for large images
    client_max_body_size 50M;

    # Health check endpoint
    location /health {
        proxy_pass http://vllm_backend/health;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        access_log off;
    }

    # OpenAI-compatible API endpoints
    location / {
        proxy_pass http://vllm_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Disable buffering for streaming responses
        proxy_buffering off;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        
        # Add headers for debugging
        add_header X-Proxy-Backend vllm-nanonets-ocr always;
    }

    # Metrics endpoint
    location /metrics {
        proxy_pass http://vllm_backend/metrics;
        proxy_set_header Host $host;
        access_log off;
    }

    # Access logs
    access_log /var/log/nginx/vllm_access.log;
    error_log /var/log/nginx/vllm_error.log;
}

