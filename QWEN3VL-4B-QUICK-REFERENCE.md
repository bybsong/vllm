# Qwen3-VL-4B Quick Reference Card

## ğŸš€ Fastest Way to Switch Modes

```powershell
# High performance (24GB) - use alone
.\scripts\switch-qwen3vl-4b-mode.ps1 standalone

# Memory efficient (16GB) - use with marker
.\scripts\switch-qwen3vl-4b-mode.ps1 shared

# Check what's running
.\scripts\switch-qwen3vl-4b-mode.ps1 status
```

## ğŸ“Š Mode Comparison (One Glance)

|                    | **Standalone** | **Shared** |
|--------------------|----------------|------------|
| **VRAM**           | 24GB           | 16GB       |
| **Context**        | 8K tokens      | 4K tokens  |
| **Concurrent**     | 3 requests     | 2 requests |
| **With Marker?**   | âŒ No          | âœ… Yes     |
| **Performance**    | Maximum        | Good       |

## ğŸ¯ Which Mode Should I Use?

**Choose STANDALONE if:**
- Running Qwen3-VL-4B alone
- Need full 8K context
- Want max throughput

**Choose SHARED if:**
- Running with marker
- Need to save VRAM
- 4K context is enough

## ğŸ”§ Manual Commands (If Script Doesn't Work)

### Standalone
```powershell
docker-compose --profile qwen3vl-4b up -d vllm-qwen3vl-4b
```

### Shared
```powershell
docker-compose --profile qwen3vl-4b-shared up -d vllm-qwen3vl-4b-shared
```

### Stop
```powershell
docker-compose stop vllm-qwen3vl-4b
```

## ğŸ” Check VRAM Usage

```powershell
nvidia-smi
# or
docker exec vllm-qwen3vl-4b nvidia-smi
```

**Expected:**
- Standalone: ~20-24GB
- Shared: ~14-18GB

## ğŸ¥ Health Check

```powershell
curl http://localhost:8005/health
curl http://localhost:8005/v1/models
```

## ğŸ“ With Marker (Shared Mode)

```powershell
# 1. Start Qwen3-VL-4B in shared mode
.\scripts\switch-qwen3vl-4b-mode.ps1 shared

# 2. Wait for startup (30-60 sec)
docker logs -f vllm-qwen3vl-4b

# 3. Start marker
docker-compose up -d marker  # adjust to your setup

# 4. Verify both running
nvidia-smi  # Should show ~28-30GB total
```

## âš ï¸ Common Issues

**"Container already exists"**
```powershell
docker rm -f vllm-qwen3vl-4b
```

**"Still using 24GB"**
```powershell
# You started wrong profile
.\scripts\switch-qwen3vl-4b-mode.ps1 shared
```

**"Out of memory"**
```powershell
# Check what's using GPU
nvidia-smi
# Stop other containers or reduce to 0.45
```

## ğŸ“š Full Documentation

- **Mode Switching Guide**: `QWEN3VL-4B-MODE-SWITCHING.md`
- **Implementation Details**: `QWEN3VL-4B-DUAL-CONFIG-SUMMARY.md`
- **This Card**: `QWEN3VL-4B-QUICK-REFERENCE.md`

## ğŸ’¾ VRAM Allocation With Marker

```
32GB RTX 5090
â”œâ”€ Qwen3-VL-4B (shared):  16GB
â”œâ”€ Marker models:          6GB
â”œâ”€ Marker working:         8GB
â””â”€ System overhead:        2GB
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   TOTAL:                ~30GB âœ…
```

## âš¡ Performance Impact (Shared vs Standalone)

- Context: **50% shorter** (4K vs 8K)
- Concurrency: **33% fewer** (2 vs 3 requests)
- Latency: **~10% slower**
- Quality: **No change** (still BF16)

## ğŸ¬ First Time Setup

```powershell
# 1. Test standalone first
.\scripts\switch-qwen3vl-4b-mode.ps1 standalone
docker logs -f vllm-qwen3vl-4b

# 2. Test shared mode
.\scripts\switch-qwen3vl-4b-mode.ps1 shared
docker exec vllm-qwen3vl-4b nvidia-smi

# 3. Add marker and verify
docker-compose up -d marker
nvidia-smi  # Check total usage
```

---

**ğŸ”— Same API endpoint for both modes:**  
`http://localhost:8005/v1/chat/completions`

**ğŸ”„ Switch anytime - no downtime needed for other services**

